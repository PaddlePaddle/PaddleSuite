Hpi:
  backend_config:
    onnx_runtime:
      cpu_num_threads: 8
    paddle_infer:
      cpu_num_threads: 8
      enable_log_info: false
    paddle_tensorrt:
      dynamic_shapes:
        im_shape:
        - - 1
          - 2
        - - 1
          - 2
        - - 1
          - 2
        image:
        - []
        - []
        - []
        scale_factor:
        - - 1
          - 2
        - - 1
          - 2
        - - 1
          - 2
      enable_log_info: false
      max_batch_size: null
    tensorrt:
      dynamic_shapes:
        im_shape:
        - - 1
          - 2
        - - 1
          - 2
        - - 1
          - 2
        image:
        - []
        - []
        - []
        scale_factor:
        - - 1
          - 2
        - - 1
          - 2
        - - 1
          - 2
      max_batch_size: null
  selected_backends:
    cpu: onnx_runtime
    gpu: tensorrt
  supported_backends:
    cpu:
    - paddle_infer
    - onnx_runtime
    gpu:
    - paddle_infer
    - paddle_tensorrt
    - onnx_runtime
    - tensorrt
